{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"238px"},"toc_section_display":true,"toc_window_display":true},"colab":{"name":"pfrl_getting_start_part3.ipynb","provenance":[],"collapsed_sections":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"f391661449554cbba1990c8d40ccd23c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bbc38edeedbf43f8a70b9e941eaee027","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_07f26f07b73e4bc5846c8576e82d9337","IPY_MODEL_d4984c3acfeb4da088ecd1f544b05903"]}},"bbc38edeedbf43f8a70b9e941eaee027":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"07f26f07b73e4bc5846c8576e82d9337":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_06fcd5daee0d4c9abcb39aff8c8a0c4b","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b7d279789897406b958bd6d71f4c97d3"}},"d4984c3acfeb4da088ecd1f544b05903":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_adfe70c65e1c4f81bcb60eaf26167945","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [1:43:54&lt;00:00,  6.23s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a1e3be3eb59c4c16be2898dd86a0919f"}},"06fcd5daee0d4c9abcb39aff8c8a0c4b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b7d279789897406b958bd6d71f4c97d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"adfe70c65e1c4f81bcb60eaf26167945":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a1e3be3eb59c4c16be2898dd86a0919f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"TdIsU98PQUYS"},"source":["# 方策ベースの機械学習2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfUi9i8uRkZu","executionInfo":{"status":"ok","timestamp":1611808748263,"user_tz":-540,"elapsed":123142,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}},"outputId":"d5d1c8f7-fd28-4f8b-840b-ca6b3de89d36"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-23T02:30:29.011030Z","start_time":"2021-01-23T02:30:29.001056Z"},"id":"08u2tCaVQUY9","executionInfo":{"status":"ok","timestamp":1611812144474,"user_tz":-540,"elapsed":1458,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}}},"source":["import sys"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RxkkpDI7QUZD"},"source":["## pfrlパッケージのパスへの追加 "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-23T02:30:31.006690Z","start_time":"2021-01-23T02:30:30.994729Z"},"id":"ftuXAQSFQUZF","executionInfo":{"status":"ok","timestamp":1611812145165,"user_tz":-540,"elapsed":1098,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}}},"source":["sys.path.append(\"/content/gdrive/MyDrive/repos/pfrl\")"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bp8ecSoaQUZJ"},"source":["## インポート "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-23T02:30:36.139994Z","start_time":"2021-01-23T02:30:31.833477Z"},"id":"iyQggslPQUZL","executionInfo":{"status":"ok","timestamp":1611812174397,"user_tz":-540,"elapsed":28679,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}}},"source":["import pfrl\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-23T02:30:36.159901Z","start_time":"2021-01-23T02:30:36.147932Z"},"id":"vlfgRUUjQUZN","executionInfo":{"status":"ok","timestamp":1611812174408,"user_tz":-540,"elapsed":22781,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}}},"source":["from tqdm.notebook import tqdm\n","import cv2"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AOrNsXMsYORG"},"source":["### 描画のための処理"]},{"cell_type":"markdown","metadata":{"id":"ea1-sAbzYNht"},"source":["[こちら](https://stackoverflow.com/a/61318224)あるいは[こちら](https://stackoverflow.com/a/61318224)を参考にした．"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"34iGHFXFUr09","executionInfo":{"status":"ok","timestamp":1611811761008,"user_tz":-540,"elapsed":47036,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}},"outputId":"e2f17031-f50d-4fee-cf4f-62f5fc3f122d"},"source":["!apt-get install -y xvfb x11-utils\r\n","!pip install -q gym[box2d]==0.17.* pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.*"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  libxxf86dga1\n","Suggested packages:\n","  mesa-utils\n","The following NEW packages will be installed:\n","  libxxf86dga1 x11-utils xvfb\n","0 upgraded, 3 newly installed, 0 to remove and 13 not upgraded.\n","Need to get 993 kB of archives.\n","After this operation, 2,981 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.8 [784 kB]\n","Fetched 993 kB in 1s (1,351 kB/s)\n","Selecting previously unselected package libxxf86dga1:amd64.\n","(Reading database ... 146374 files and directories currently installed.)\n","Preparing to unpack .../libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n","Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n","Selecting previously unselected package x11-utils.\n","Preparing to unpack .../x11-utils_7.7+3build1_amd64.deb ...\n","Unpacking x11-utils (7.7+3build1) ...\n","Selecting previously unselected package xvfb.\n","Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.8_amd64.deb ...\n","Unpacking xvfb (2:1.19.6-1ubuntu4.8) ...\n","Setting up xvfb (2:1.19.6-1ubuntu4.8) ...\n","Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n","Setting up x11-utils (7.7+3build1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","\u001b[K     |████████████████████████████████| 542kB 5.2MB/s \n","\u001b[K     |████████████████████████████████| 450kB 6.9MB/s \n","\u001b[?25h  Building wheel for PyOpenGL-accelerate (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zxPHPkUvdus0","executionInfo":{"status":"ok","timestamp":1611811761018,"user_tz":-540,"elapsed":16298,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}}},"source":["import pyvirtualdisplay\r\n","_display = pyvirtualdisplay.Display(visible=False,  # use False with Xvfb\r\n","                                    size=(1400, 900))\r\n","_ = _display.start()"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9chnzZV0QUZP"},"source":["## 離散行動・確率方策(リベンジ) "]},{"cell_type":"code","metadata":{"id":"_bwIPFu7fOsP","executionInfo":{"status":"ok","timestamp":1611812115443,"user_tz":-540,"elapsed":1370,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}}},"source":["import gym"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pjkZLzBIQUZR"},"source":["前回のa2cによるペンデュラムの強化学習がうまくいかなかったので，今回はsoft-actor-criticで学習を行う．"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-23T02:30:37.692802Z","start_time":"2021-01-23T02:30:37.619995Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"NthzTo4fQUZU","executionInfo":{"status":"ok","timestamp":1611812118312,"user_tz":-540,"elapsed":699,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}},"outputId":"ec11c767-015d-4871-9076-d85f00ebf273"},"source":["concrete_env = gym.make(\"Pendulum-v0\")\n","print(\"observation space:\", concrete_env.observation_space)\n","print(\"action space:\", concrete_env.action_space)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["observation space: Box(-8.0, 8.0, (3,), float32)\n","action space: Box(-2.0, 2.0, (1,), float32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m2Fp7mc_QUZb"},"source":["### モデルの定義"]},{"cell_type":"markdown","metadata":{"id":"43D81nrYQUZd"},"source":["モデルの構造はDDPGとほとんど一緒で，状態を入力として行動を出力する方策モデル(今回は確率を出力)と，状態と行動を入力として価値関数を出力する価値関数が必要である．"]},{"cell_type":"markdown","metadata":{"id":"xWtDZWwUQUZf"},"source":["#### 方策モデルの定義 "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-20T00:38:34.455747Z","start_time":"2021-01-20T00:38:34.415853Z"},"id":"CHZR08NbQUZh","executionInfo":{"status":"ok","timestamp":1611812230505,"user_tz":-540,"elapsed":793,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}}},"source":["class PolicyModel(nn.Module):\n","    def __init__(self, obs_size, action_dim, action_low, action_high):\n","        super().__init__()\n","        self.fc1 = nn.Linear(obs_size, 50)\n","        self.fc2 = nn.Linear(50, 50)\n","        self.fc3 = nn.Linear(50, action_dim)\n","        self.policy_bound = pfrl.nn.BoundByTanh(action_low, action_high)\n","        self.policy_head = pfrl.policies.GaussianHeadWithFixedCovariance(0.1)\n","        \n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        \n","        #policy_x = F.relu(self.fc3(x))\n","        #policy_x = self.fc3(x)\n","        policy_x = 2 * torch.tanh(self.fc3(x))\n","        #policy_x =  self.policy_bound(self.fc3(x))\n","        out_policy = self.policy_head(policy_x)\n","        return out_policy"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-20T00:43:09.664997Z","start_time":"2021-01-20T00:43:09.605159Z"},"id":"Wr0ThbObQUZk","executionInfo":{"status":"ok","timestamp":1611812233966,"user_tz":-540,"elapsed":683,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}}},"source":["obs_size = concrete_env.observation_space.low.size\n","action_dim = concrete_env.action_space.low.size\n","action_low = concrete_env.action_space.low\n","action_high = concrete_env.action_space.high\n","\n","policy_model = PolicyModel(obs_size, action_dim, action_low, action_high)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SRaajKlQQUZm"},"source":["#### Q関数 "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-20T00:39:48.990490Z","start_time":"2021-01-20T00:39:48.954584Z"},"id":"aHEN54QNQUZn","executionInfo":{"status":"ok","timestamp":1611812391870,"user_tz":-540,"elapsed":1153,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}}},"source":["class QFunc(nn.Module):\n","    def __init__(self, obs_size, action_dim):\n","        super().__init__()\n","        self.concat_obs_action = pfrl.nn.ConcatObsAndAction()\n","        self.fc1 = nn.Linear(obs_size+action_dim, 50)\n","        self.fc2 = nn.Linear(50, 50)\n","        self.fc3 = nn.Linear(50, 1)\n","        \n","    def forward(self, x):\n","        x = self.concat_obs_action(x)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)  # 最後は活性化関数は必要は無い\n","        return x"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-20T00:43:38.282471Z","start_time":"2021-01-20T00:43:38.264517Z"},"id":"179EiUuaQUZq","executionInfo":{"status":"ok","timestamp":1611812392249,"user_tz":-540,"elapsed":1081,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}}},"source":["q_func1 = QFunc(obs_size, action_dim)\n","q_func2 = QFunc(obs_size, action_dim)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RnbgtRxWQUZt"},"source":["#### マルチプロセス用のバッチ環境 "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-20T00:45:08.241889Z","start_time":"2021-01-20T00:45:08.221944Z"},"id":"PRexodCLQUZu","executionInfo":{"status":"ok","timestamp":1611812453851,"user_tz":-540,"elapsed":1205,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}}},"source":["sys.path.append(\"/content/gdrive/MyDrive/rl_tutorial\")\r\n","from tutorial_make_env_ver1 import make_concrete_env"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-20T00:47:45.736766Z","start_time":"2021-01-20T00:47:38.254784Z"},"id":"gGlxNIM9QUZw","executionInfo":{"status":"ok","timestamp":1611812456821,"user_tz":-540,"elapsed":1027,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}}},"source":["process_number = 4\n","batch_concrete_env = pfrl.envs.MultiprocessVectorEnv([make_concrete_env for i in range(process_number)])"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YREE6An6QUZy"},"source":["#### エージェントの定義 "]},{"cell_type":"markdown","metadata":{"id":"ExU69G9bQUZz"},"source":["ハイパーパラメータはこちらを参考とした([参考](https://github.com/pfnet/pfrl/blob/master/examples/mujoco/reproduction/soft_actor_critic/train_soft_actor_critic.py))．"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-20T01:05:16.381496Z","start_time":"2021-01-20T01:05:16.318664Z"},"id":"oSDIdOfrQUZ2","executionInfo":{"status":"ok","timestamp":1611812464565,"user_tz":-540,"elapsed":732,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}}},"source":["policy_optimizer = torch.optim.Adam(policy_model.parameters(), lr=3e-4)\n","q_func1_optimizer = torch.optim.Adam(q_func1.parameters(), lr=3e-4)\n","q_func2_optimizer = torch.optim.Adam(q_func2.parameters(), lr=3e-4)\n","\n","rbuf = pfrl.replay_buffers.ReplayBuffer(10 ** 6)\n","\n","def burnin_action_func():\n","    \"\"\"Select random actions until model is updated one or more times.\"\"\"\n","    return np.random.uniform(concrete_env.action_space.low, concrete_env.action_space.high).astype(np.float32)\n","\n","gpu = -1\n","\n","gamma = 0.99 \n","\n","replay_start_size =10000\n","\n","#batch_size = 256\n","batch_size = 16  # 環境の数と異なることに注意\n","\n","phi = lambda x: x.astype(np.float32, copy=False)\n","\n","sac_agent = pfrl.agents.SoftActorCritic(\n","    policy_model,\n","    q_func1,\n","    q_func2,\n","    policy_optimizer,\n","    q_func1_optimizer,\n","    q_func2_optimizer,\n","    rbuf,\n","    phi=phi,\n","    gamma=gamma,\n","    replay_start_size=replay_start_size,\n","    gpu=gpu,\n","    minibatch_size=batch_size,\n","    burnin_action_func=burnin_action_func,\n","    entropy_target=-action_dim,\n","    temperature_optimizer_lr=3e-4,\n",")"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RdeQ2xYQQUZ3"},"source":["### 学習のイテレーション"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-20T05:01:15.833522Z","start_time":"2021-01-20T01:05:17.232218Z"},"colab":{"base_uri":"https://localhost:8080/","height":629,"referenced_widgets":["f391661449554cbba1990c8d40ccd23c","bbc38edeedbf43f8a70b9e941eaee027","07f26f07b73e4bc5846c8576e82d9337","d4984c3acfeb4da088ecd1f544b05903","06fcd5daee0d4c9abcb39aff8c8a0c4b","b7d279789897406b958bd6d71f4c97d3","adfe70c65e1c4f81bcb60eaf26167945","a1e3be3eb59c4c16be2898dd86a0919f"]},"id":"8L1iKd08QUZ5","executionInfo":{"status":"ok","timestamp":1611818713985,"user_tz":-540,"elapsed":4588263,"user":{"displayName":"Naoto Asami","photoUrl":"","userId":"02738946460850472304"}},"outputId":"ec30acbe-9940-4b85-d336-9167e6bbd7bd"},"source":["n_episodes = 1000  # エピソードの回数\n","max_episode_len = 200\n","for i in tqdm(range(1, n_episodes + 1)):\n","    \n","    obss = batch_concrete_env.reset()  # 観測のリセット\n","    R = np.zeros((process_number,))  # Return (sum ofrewards)\n","    t = 0  # time step\n","    while True:\n","        actions = sac_agent.batch_act(obss)\n","        obss, rewards, dones, _ = batch_concrete_env.step(actions)\n","        \n","        R += rewards\n","        t += 1\n","        \n","        resets = np.array([t == max_episode_len]*process_number)\n","        sac_agent.batch_observe(obss, rewards, dones, resets)\n","        if resets[0]:\n","            break\n","    \n","    if i%50 == 0:\n","        print(\"episode:{}, return:{}, t:{}\".format(i, R, t))\n","    if i%100 == 0:\n","        print(\"statistics:\", sac_agent.get_statistics())\n","print(\"Finshed\")\n","batch_concrete_env.close()  # バッチで利用する場合は明示的にクローズ"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f391661449554cbba1990c8d40ccd23c","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["episode:50, return:[-746.362587   -494.24369095 -754.00234931 -359.87311801], t:200\n","episode:100, return:[-642.7930444  -640.47807826 -637.48804755 -638.82893383], t:200\n","statistics: [('average_q1', -250.6291), ('average_q2', -250.6312), ('average_q_func1_loss', 175.21573196768762), ('average_q_func2_loss', 176.61977141141892), ('n_updates', 70001), ('average_entropy', -0.8836467), ('temperature', 5.087737736175768e-05)]\n","episode:150, return:[-196.29735236 -377.60357015 -367.33380597 -249.75897006], t:200\n","episode:200, return:[-119.67303694 -124.00614839   -1.24901911 -124.68486302], t:200\n","statistics: [('average_q1', -89.653534), ('average_q2', -89.59766), ('average_q_func1_loss', 12.165641034841537), ('average_q_func2_loss', 14.66298926949501), ('n_updates', 150001), ('average_entropy', -0.8836467), ('temperature', 1.2979199048857026e-08)]\n","episode:250, return:[-122.15057359 -121.97837793 -118.13973578 -221.19352129], t:200\n","episode:300, return:[-118.48758547 -119.4090003  -117.41768661 -122.81422822], t:200\n","statistics: [('average_q1', 7.9578595), ('average_q2', 7.977413), ('average_q_func1_loss', 6.969498963654042), ('average_q_func2_loss', 5.629653011262417), ('n_updates', 230001), ('average_entropy', -0.8836467), ('temperature', 3.080772748020877e-09)]\n","episode:350, return:[-115.9437315  -117.64787681 -114.49898107 -119.87778596], t:200\n","episode:400, return:[-134.63656987 -125.60820358 -132.28237731 -132.34134953], t:200\n","statistics: [('average_q1', -27.64187), ('average_q2', -27.63254), ('average_q_func1_loss', 6.5380283407866955), ('average_q_func2_loss', 6.592681780010462), ('n_updates', 310001), ('average_entropy', -0.8836467), ('temperature', 1.6987604656293342e-09)]\n","episode:450, return:[-309.42994278 -126.04512368 -126.58572881 -126.81416746], t:200\n","episode:500, return:[-127.08911224 -122.52498558 -126.46688716 -127.00480534], t:200\n","statistics: [('average_q1', -29.01834), ('average_q2', -28.99399), ('average_q_func1_loss', 5.514078926108778), ('average_q_func2_loss', 5.439598196297884), ('n_updates', 390001), ('average_entropy', -0.8836467), ('temperature', 1.1652795395278304e-09)]\n","episode:550, return:[  -9.90585595 -133.98586604 -130.74356791 -127.58585072], t:200\n","episode:600, return:[-126.15196039  -11.69421546   -0.67231829 -121.83340403], t:200\n","statistics: [('average_q1', -27.97888), ('average_q2', -27.922283), ('average_q_func1_loss', 1.992100247517228), ('average_q_func2_loss', 1.6767277686297895), ('n_updates', 470001), ('average_entropy', -0.8836467), ('temperature', 8.838674236955057e-10)]\n","episode:650, return:[-128.91030912 -118.3948015  -337.8388534  -119.69563329], t:200\n","episode:700, return:[-347.84510047   -7.32699236 -120.69156182   -5.95469424], t:200\n","statistics: [('average_q1', -18.562973), ('average_q2', -18.56546), ('average_q_func1_loss', 6.698565950319171), ('average_q_func2_loss', 6.26995918225497), ('n_updates', 550001), ('average_entropy', -0.8836467), ('temperature', 7.110125266329703e-10)]\n","episode:750, return:[-127.74907702 -236.9865777  -228.94322138 -134.1534984 ], t:200\n","episode:800, return:[-343.50496477 -124.34956504 -223.09814739 -127.99888211], t:200\n","statistics: [('average_q1', -24.809961), ('average_q2', -24.742764), ('average_q_func1_loss', 3.6928559330664577), ('average_q_func2_loss', 3.856326911598444), ('n_updates', 630001), ('average_entropy', -0.8836467), ('temperature', 5.952085491145453e-10)]\n","episode:850, return:[-130.69035942 -125.53487114 -233.88214335 -244.72826837], t:200\n","episode:900, return:[  -8.09382292 -122.15426679 -125.20957819 -123.31323791], t:200\n","statistics: [('average_q1', -22.943645), ('average_q2', -22.927776), ('average_q_func1_loss', 7.144664872065187), ('average_q_func2_loss', 6.315525690591894), ('n_updates', 710001), ('average_entropy', -0.8836467), ('temperature', 5.105460498810999e-10)]\n","episode:950, return:[-246.29079973 -245.30194911 -124.13449436 -230.21881212], t:200\n","episode:1000, return:[-123.91635516   -8.61227126 -237.77804279 -127.66878861], t:200\n","statistics: [('average_q1', -22.040005), ('average_q2', -22.038162), ('average_q_func1_loss', 28.5462842688337), ('average_q_func2_loss', 29.110486825937404), ('n_updates', 790001), ('average_entropy', -0.8836467), ('temperature', 4.442042567109894e-10)]\n","\n","Finshed\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hHyGvRxvQUZ8"},"source":["#### 学習結果の可視化 "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-20T05:01:28.138812Z","start_time":"2021-01-20T05:01:15.854466Z"},"id":"S8zjSW0oQUZ-","outputId":"7246ad62-5346-49c3-8d63-ba7eb66618cc"},"source":["fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n","out = cv2.VideoWriter('movies/tutorial/pfrl_tutorial_sac_result.mp4', fourcc, 10, (500, 500))\n","\n","max_episode_len = 200\n","with sac_agent.eval_mode():\n","    \n","    obs = concrete_env.reset()  # 観測のリセット\n","    R = 0  # Return (sum ofrewards)\n","    t = 0  # time step\n","    \n","    while True:\n","        action = sac_agent.act(obs)\n","        obs, reward, done, _ = concrete_env.step(action)\n","        R += reward\n","        t += 1\n","        reset = t == max_episode_len\n","        # 画像として取得，保存\n","        frame = concrete_env.render(mode=\"rgb_array\")\n","        out.write(frame[:,:,::-1])       \n","        \n","        #sac_agent.observe(obs, reward, done, reset)\n","        if done or reset:\n","            break\n","            \n","concrete_env.close()\n","out.release()\n","\n","print(\"episode length:\", t)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["episode length: 200\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_syVg5E8QUaB"},"source":["## 他のモデルもお試し "]},{"cell_type":"markdown","metadata":{"id":"0Aw_mL08QUaC"},"source":["### TRPO "]},{"cell_type":"markdown","metadata":{"id":"4e8v4NesQUaD"},"source":["#### モデルの定義 "]},{"cell_type":"markdown","metadata":{"id":"Na2Apim7QUaG"},"source":["##### 方策モデルの定義"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-23T02:47:41.715230Z","start_time":"2021-01-23T02:47:41.676332Z"},"id":"r4JUxtB2QUaH"},"source":["class PolicyModel(nn.Module):\n","    def __init__(self, obs_size, action_dim, action_low, action_high):\n","        super().__init__()\n","        self.fc1 = nn.Linear(obs_size, 50)\n","        self.fc2 = nn.Linear(50, 50)\n","        self.fc3 = nn.Linear(50, action_dim)\n","        self.policy_bound = pfrl.nn.BoundByTanh(action_low, action_high)\n","        self.policy_head = pfrl.policies.GaussianHeadWithFixedCovariance(0.1)\n","        \n","    def forward(self, x):\n","        x = torch.tanh(self.fc1(x))\n","        x = torch.tanh(self.fc2(x))\n","        \n","        #policy_x = F.relu(self.fc3(x))\n","        #policy_x = self.fc3(x)\n","        policy_x = 2 * torch.tanh(self.fc3(x))\n","        #policy_x =  self.policy_bound(self.fc3(x))\n","        out_policy = self.policy_head(policy_x)\n","        return out_policy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-23T02:47:45.477162Z","start_time":"2021-01-23T02:47:45.456218Z"},"id":"m_TmnOwXQUaK"},"source":["obs_size = concrete_env.observation_space.low.size\n","action_dim = concrete_env.action_space.low.size\n","action_low = concrete_env.action_space.low\n","action_high = concrete_env.action_space.high\n","\n","policy_model = PolicyModel(obs_size, action_dim, action_low, action_high)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BkJuIhMrQUaM"},"source":["##### 価値関数の定義 "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-23T03:08:27.862761Z","start_time":"2021-01-23T03:08:27.832838Z"},"id":"FmyimHENQUaQ"},"source":["class VFunc(nn.Module):\n","    def __init__(self, obs_size):\n","        super().__init__()\n","        self.fc1 = nn.Linear(obs_size, 50)\n","        self.fc2 = nn.Linear(50, 50)\n","        self.fc3 = nn.Linear(50, 1)\n","        \n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)  # 最後は活性化関数は必要は無い\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-23T03:08:29.188221Z","start_time":"2021-01-23T03:08:29.174249Z"},"id":"G6tdLAQgQUaT"},"source":["v_func = VFunc(obs_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2021-01-23T02:36:28.936852Z","start_time":"2021-01-23T02:36:28.693500Z"},"id":"gAUR4BicQUaV"},"source":["#### 重みの初期化"]},{"cell_type":"markdown","metadata":{"id":"0lSlZ4WbQUaX"},"source":["もとのexampleでは，直交行列による初期化が行われている．"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-23T03:08:31.336466Z","start_time":"2021-01-23T03:08:31.291590Z"},"id":"kKa1e3JVQUaY"},"source":["def ortho_init(layer, gain):\n","    nn.init.orthogonal_(layer.weight, gain=gain)\n","    nn.init.zeros_(layer.bias)\n","    \n","ortho_init(policy_model.fc1, gain=1)\n","ortho_init(policy_model.fc2, gain=1)\n","ortho_init(policy_model.fc3, gain=1e-2)\n","ortho_init(v_func.fc1, gain=1)\n","ortho_init(v_func.fc2, gain=1)\n","ortho_init(v_func.fc3, gain=1e-2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nsQyoe6QQUaa"},"source":["#### 最適化手法"]},{"cell_type":"markdown","metadata":{"id":"u3TY047WQUaf"},"source":["TRPOの最適化手法は方策モデルについては特殊な手法を用いるので，深層学習による最適化は価値関数に対してのみ行う．"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-23T03:08:32.744698Z","start_time":"2021-01-23T03:08:32.733725Z"},"id":"MaPXP8-yQUah"},"source":["vf_opt = torch.optim.Adam(v_func.parameters())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yyTIO8GnQUai"},"source":["#### エージェントの定義 "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-23T03:08:33.559516Z","start_time":"2021-01-23T03:08:33.529597Z"},"id":"FZOuwzZwQUak"},"source":["obs_normalizer = pfrl.nn.EmpiricalNormalization(\n","    concrete_env.observation_space.low.size, clip_threshold=5\n",")\n","\n","gpu = -1\n","\n","trpo_update_interval = 5000\n","\n","phi = lambda x: x.astype(np.float32, copy=False)\n","\n","\n","trpo_agent = pfrl.agents.TRPO(\n","    policy=policy_model,\n","    vf=v_func,\n","    vf_optimizer=vf_opt,\n","    obs_normalizer=obs_normalizer,\n","    gpu=gpu,\n","    update_interval=trpo_update_interval,\n","    phi=phi,\n","    max_kl=0.01,\n","    conjugate_gradient_max_iter=20,\n","    conjugate_gradient_damping=1e-1,\n","    gamma=0.995,\n","    lambd=0.97,\n","    vf_epochs=5,\n","    entropy_coef=0,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LPSdnv3bQUam"},"source":["#### 学習のイテレーション "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-23T03:16:38.734275Z","start_time":"2021-01-23T03:08:34.500998Z"},"colab":{"referenced_widgets":["596ae440cc8b4415b5176574a799c1e8"]},"id":"4ff4aat_QUap","outputId":"c3038c0f-245f-47e0-d4bc-ca8c3c9d5d54"},"source":["n_episodes = 1000  # エピソードの回数\n","max_episode_len = 200\n","for i in tqdm(range(1, n_episodes + 1)):\n","    obs = concrete_env.reset()  # 観測のリセット\n","    R = 0  # Return (sum ofrewards)\n","    t = 0  # time step\n","    while True:\n","        action = trpo_agent.act(obs)\n","        obs, reward, done, _ = concrete_env.step(action)\n","        R += reward\n","        t += 1\n","        reset = t == max_episode_len\n","        trpo_agent.observe(obs, reward, done, reset)\n","        if done or reset:\n","            break\n","    \n","    if i%50 == 0:\n","        print(\"episode:{}, return:{}\".format(i, R))\n","    if i%100 == 0:\n","        print(\"statistics:\", trpo_agent.get_statistics())\n","        \n","print(\"Finshed\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"596ae440cc8b4415b5176574a799c1e8","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["episode:50, return:-956.3156095101926\n","episode:100, return:-1601.5568378078367\n","statistics: [('average_value', -342.63205), ('average_entropy', -0.8836467), ('average_kl', 0.005610514956060797), ('average_policy_step_size', 0.75), ('explained_variance', 0.17451641137397245)]\n","episode:150, return:-1179.2167101503494\n","episode:200, return:-1070.0198208647985\n","statistics: [('average_value', -504.7983), ('average_entropy', -0.8836467), ('average_kl', 0.005198648635996506), ('average_policy_step_size', 0.75), ('explained_variance', 0.06952748522986674)]\n","episode:250, return:-1564.118827835543\n","episode:300, return:-1790.6384953417025\n","statistics: [('average_value', -577.014), ('average_entropy', -0.8836467), ('average_kl', 0.005378205969464034), ('average_policy_step_size', 0.75), ('explained_variance', 0.13961949396502193)]\n","episode:350, return:-1838.052834409432\n","episode:400, return:-887.4082104080612\n","statistics: [('average_value', -562.13275), ('average_entropy', -0.8836467), ('average_kl', 0.004578063613735139), ('average_policy_step_size', 0.6875), ('explained_variance', 0.1501032390986231)]\n","episode:450, return:-1086.1225582834525\n","episode:500, return:-1309.0770864357885\n","statistics: [('average_value', -560.51044), ('average_entropy', -0.8836467), ('average_kl', 0.004555678018368781), ('average_policy_step_size', 0.7), ('explained_variance', 0.10760667372480748)]\n","episode:550, return:-1893.3624787915464\n","episode:600, return:-1537.7983295188894\n","statistics: [('average_value', -583.76514), ('average_entropy', -0.8836467), ('average_kl', 0.0043396503606345505), ('average_policy_step_size', 0.6875), ('explained_variance', 0.13017899038639547)]\n","episode:650, return:-1315.3293224349052\n","episode:700, return:-1288.3043714138291\n","statistics: [('average_value', -556.55365), ('average_entropy', -0.8836467), ('average_kl', 0.004274695246879544), ('average_policy_step_size', 0.6785714285714286), ('explained_variance', 0.11247738017547615)]\n","episode:750, return:-1177.5994361689372\n","episode:800, return:-972.0012295243524\n","statistics: [('average_value', -543.60596), ('average_entropy', -0.8836467), ('average_kl', 0.004623997607268393), ('average_policy_step_size', 0.703125), ('explained_variance', 0.07473164307843627)]\n","episode:850, return:-1361.4679228936266\n","episode:900, return:-1167.9865928348938\n","statistics: [('average_value', -568.7453), ('average_entropy', -0.8836467), ('average_kl', 0.0047780654664772255), ('average_policy_step_size', 0.7083333333333334), ('explained_variance', 0.03245563970368537)]\n","episode:950, return:-1734.152117948269\n","episode:1000, return:-1250.9078220527915\n","statistics: [('average_value', -590.96686), ('average_entropy', -0.8836467), ('average_kl', 0.004845425602979958), ('average_policy_step_size', 0.7125), ('explained_variance', 0.04652796412689009)]\n","\n","Finshed\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"13kX_hy0QUas"},"source":["### PPO "]},{"cell_type":"code","metadata":{"id":"2LrT__OoQUau"},"source":[""],"execution_count":null,"outputs":[]}]}